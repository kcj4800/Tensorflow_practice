{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "mount_file_id": "19gwdjRqJFfxkL1JTPJSsh3wK1yY-xRN1",
      "authorship_tag": "ABX9TyOo7s1BpTNYCqznL//evoeY",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kcj4800/Tensorflow_practice/blob/main/Titanic_Survived.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yQ9ebvAsij8h",
        "outputId": "0199bc98-5d6f-4a4e-8ff5-c4cdf2db2753"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     PassengerId  Survived  Pclass  \\\n",
            "0              1         0       3   \n",
            "1              2         1       1   \n",
            "2              3         1       3   \n",
            "3              4         1       1   \n",
            "4              5         0       3   \n",
            "..           ...       ...     ...   \n",
            "886          887         0       2   \n",
            "887          888         1       1   \n",
            "888          889         0       3   \n",
            "889          890         1       1   \n",
            "890          891         0       3   \n",
            "\n",
            "                                                  Name     Sex   Age  SibSp  \\\n",
            "0                              Braund, Mr. Owen Harris    male  22.0      1   \n",
            "1    Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
            "2                               Heikkinen, Miss. Laina  female  26.0      0   \n",
            "3         Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
            "4                             Allen, Mr. William Henry    male  35.0      0   \n",
            "..                                                 ...     ...   ...    ...   \n",
            "886                              Montvila, Rev. Juozas    male  27.0      0   \n",
            "887                       Graham, Miss. Margaret Edith  female  19.0      0   \n",
            "888           Johnston, Miss. Catherine Helen \"Carrie\"  female   NaN      1   \n",
            "889                              Behr, Mr. Karl Howell    male  26.0      0   \n",
            "890                                Dooley, Mr. Patrick    male  32.0      0   \n",
            "\n",
            "     Parch            Ticket     Fare Embarked  \n",
            "0        0         A/5 21171   7.2500        S  \n",
            "1        0          PC 17599  71.2833        C  \n",
            "2        0  STON/O2. 3101282   7.9250        S  \n",
            "3        0            113803  53.1000        S  \n",
            "4        0            373450   8.0500        S  \n",
            "..     ...               ...      ...      ...  \n",
            "886      0            211536  13.0000        S  \n",
            "887      0            112053  30.0000        S  \n",
            "888      2        W./C. 6607  23.4500        S  \n",
            "889      0            111369  30.0000        C  \n",
            "890      0            370376   7.7500        Q  \n",
            "\n",
            "[891 rows x 11 columns]\n",
            "PassengerId      0\n",
            "Survived         0\n",
            "Pclass           0\n",
            "Name             0\n",
            "Sex              0\n",
            "Age            177\n",
            "SibSp            0\n",
            "Parch            0\n",
            "Ticket           0\n",
            "Fare             0\n",
            "Embarked         2\n",
            "dtype: int64\n",
            "29.69911764705882\n",
            "0    S\n",
            "Name: Embarked, dtype: object\n",
            "PassengerId    0\n",
            "Survived       0\n",
            "Pclass         0\n",
            "Name           0\n",
            "Sex            0\n",
            "Age            0\n",
            "SibSp          0\n",
            "Parch          0\n",
            "Ticket         0\n",
            "Fare           0\n",
            "Embarked       0\n",
            "dtype: int64\n"
          ]
        }
      ],
      "source": [
        "# 세로열이 많을땐 feature columns를 사용하여 자동화하자\n",
        "import pandas as pd\n",
        "import os\n",
        "\n",
        "data = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/titanic/train.csv')\n",
        "print(data)\n",
        "print(data.isnull().sum())\n",
        "\n",
        "# 평균값으로 빈칸 채우기\n",
        "age_avg = data['Age'].mean()\n",
        "print(age_avg)\n",
        "data['Age'].fillna(value=30, inplace = True)\n",
        "\n",
        "# 최빈값으로 빈칸 채우기\n",
        "Embarked_mode = data['Embarked'].mode()\n",
        "print(Embarked_mode)\n",
        "data['Embarked'].fillna(value = 'S', inplace = True)\n",
        "print(data.isnull().sum())\n",
        "# Embarked"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "\n",
        "Y = data.pop('Survived')\n",
        "X = data\n",
        "# model.fit(ds_batch, validation_data = (valX, valY), suffle = True, epochs = 20) 처럼 하기 위해서는\n",
        "# sklearn을 이용하는 방법이 있다. \n",
        "# 참고. 악플분석\n",
        "\n",
        "# from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "# X = pad_sequences(train_seq, maxlen=100)\n",
        "\n",
        "# from sklearn.model_selection import train_test_split\n",
        "\n",
        "# trainX, valX, trainY, valY = train_test_split( X, Y, test_size = 0.2, random_state = 42)\n",
        "\n",
        "# print(len(trainX))\n",
        "# print(len(valX))\n",
        "print(len(X))\n",
        "from sklearn.model_selection import train_test_split\n",
        "trainX, valX, trainY, valY = train_test_split( X, Y, test_size = 0.2, random_state = 42)\n",
        "print(len(trainX))\n",
        "print(len(valX))\n",
        "\n",
        "ds = tf.data.Dataset.from_tensor_slices( (dict(X), Y))\n",
        "\n",
        "# csv데이터를 집어넣을때 feature column을 이용하기 위해서는 이러한 형태의 dataset을 만들어야 한다.\n",
        "\n",
        "# print(ds)\n",
        "\n",
        "# for i, l in ds.take(1):\n",
        "#   print(i, l)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UJIuC1BOl5t6",
        "outputId": "228ec275-05e3-42fa-cac7-095ae87068a8"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "891\n",
            "712\n",
            "179\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 첫 레이어는 tf.keras.layers.Dense() 대신 tf.keras.layers.DenseFeatures()로 한다.\n",
        "# nomalizing : 숫자를 0 ~ 1 사이로 압축해준다.\n",
        "feature_columns = []\n",
        "numeric_columns = ['Fare', 'Parch', 'SibSp']\n",
        "\n",
        "for i in numeric_columns:\n",
        "  def normalizer_func(x):\n",
        "    최소 = data[i].min()\n",
        "    최대 = data[i].max()\n",
        "    return (x - 최소) / (최대 - 최소) # x = 최댓값일 경우 = 1, x = 최솟값일 경우 = 0 => 0 ~ 1 사이로 압축된다.\n",
        "  feature_columns.append(tf.feature_column.numeric_column(i, normalizer_fn = normalizer_func))\n",
        "\n",
        "# feature_columns.append(tf.feature_column.numeric_column('Fare', normalizer_fn = 노말라이저함수))\n",
        "# feature_columns.append(tf.feature_column.numeric_column('Parch'))\n",
        "# feature_columns.append(tf.feature_column.numeric_column('SibSp'))\n",
        "\n",
        "# feature_columns.append(tf.feature_column.numeric_column('Age'))\n",
        "\n",
        "# bucketized_column\n",
        "Age = tf.feature_column.numeric_column('Age')\n",
        "Age_bucket = tf.feature_column.bucketized_column(Age, boundaries = [10, 20, 30, 40, 50, 60])\n",
        "\n",
        "feature_columns.append(Age_bucket)\n",
        "\n",
        "\n",
        "# 각 컬럼을 어떻게 전처리할지 먼저 생각해보기\n",
        "\t\t\t\t\t\t\t\t\n",
        "# 숫자로 집어넣은것 : Fare, SibSp, Parch : numeric_column\n",
        "# 뭉퉁그려서 집어넣을거 : Age : bucketized_column\n",
        "# 종류 몇개 없는 카테고리화 해서 집어넣을거 : Sex, Embarked Pclass : indicator_column\n",
        "# 종류가 넘 많은 카테고리 : Ticket : embedding_column - 원하는 행렬로 무작위 숫자를 설정 한뒤 학습 진행하면서 적절한 숫자를 자동으로 찾는다.\n",
        "# 스킵해도 될 내용 : Name, PassengerId\n",
        "# 정답 컬럼 : Survived\n",
        "\n",
        "print(Age)\n",
        "print(feature_columns)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CK6ogYFKocHv",
        "outputId": "1f30368a-dcdb-4200-e9a5-b987d9a17b6c"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NumericColumn(key='Age', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None)\n",
            "[NumericColumn(key='Fare', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=<function normalizer_func at 0x7fe449ba9120>), NumericColumn(key='Parch', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=<function normalizer_func at 0x7fe449ba9bd0>), NumericColumn(key='SibSp', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=<function normalizer_func at 0x7fe449ba9e10>), BucketizedColumn(source_column=NumericColumn(key='Age', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None), boundaries=(10, 20, 30, 40, 50, 60))]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# sequence_categorical_column_with_vocabualary_list() -> categorical_column_with_vocabulary_list()\n",
        "# a = ['Sex', 'Embarked', 'Pclass']\n",
        "# for i in a:\n",
        "#   vocab = data[i].unique() # 'Sex' column 의 unique_words\n",
        "#   print(vocab)\n",
        "#   cat = tf.feature_column.categorical_column_with_vocabulary_list(i, vocab )\n",
        "#   one_hot = tf.feature_column.indicator_column(cat) # one_hot 인코딩해준다.\n",
        "#   feature_columns.append( one_hot )  \n",
        "\n",
        "vocab = data['Sex'].unique() # 'Sex' column 의 unique_words\n",
        "print(vocab)\n",
        "cat = tf.feature_column.categorical_column_with_vocabulary_list('Sex', vocab )\n",
        "one_hot = tf.feature_column.indicator_column(cat) # one_hot 인코딩해준다.\n",
        "feature_columns.append( one_hot )\n",
        "\n",
        "vocab = data['Embarked'].unique() # 'Embarked' column 의 unique_words\n",
        "print(vocab)\n",
        "cat = tf.feature_column.categorical_column_with_vocabulary_list('Embarked', vocab )\n",
        "one_hot = tf.feature_column.indicator_column(cat) # one_hot 인코딩해준다.\n",
        "feature_columns.append( one_hot )\n",
        "\n",
        "vocab = data['Pclass'].unique() # 'Pclass' column 의 unique_words\n",
        "print(vocab)\n",
        "cat = tf.feature_column.categorical_column_with_vocabulary_list('Pclass', vocab )\n",
        "one_hot = tf.feature_column.indicator_column(cat) # one_hot 인코딩해준다.\n",
        "feature_columns.append( one_hot )\n",
        "\n",
        "\n",
        "# embedding\n",
        "vocab = data['Ticket'].unique() # 'Ticket' column 의 unique_words\n",
        "print(vocab)\n",
        "cat = tf.feature_column.categorical_column_with_vocabulary_list('Ticket', vocab )\n",
        "one_hot = tf.feature_column.embedding_column(cat, dimension = 9) # 몇 차원의 행렬로 임베딩 할것인지 정해준다.\n",
        "feature_columns.append( one_hot )\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5htIkLAJtIv_",
        "outputId": "d68bb9d0-2dce-4e37-c0f4-8233263dd50d"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['male' 'female']\n",
            "['S' 'C' 'Q']\n",
            "[3 1 2]\n",
            "['A/5 21171' 'PC 17599' 'STON/O2. 3101282' '113803' '373450' '330877'\n",
            " '17463' '349909' '347742' '237736' 'PP 9549' '113783' 'A/5. 2151'\n",
            " '347082' '350406' '248706' '382652' '244373' '345763' '2649' '239865'\n",
            " '248698' '330923' '113788' '347077' '2631' '19950' '330959' '349216'\n",
            " 'PC 17601' 'PC 17569' '335677' 'C.A. 24579' 'PC 17604' '113789' '2677'\n",
            " 'A./5. 2152' '345764' '2651' '7546' '11668' '349253' 'SC/Paris 2123'\n",
            " '330958' 'S.C./A.4. 23567' '370371' '14311' '2662' '349237' '3101295'\n",
            " 'A/4. 39886' 'PC 17572' '2926' '113509' '19947' 'C.A. 31026' '2697'\n",
            " 'C.A. 34651' 'CA 2144' '2669' '113572' '36973' '347088' 'PC 17605' '2661'\n",
            " 'C.A. 29395' 'S.P. 3464' '3101281' '315151' 'C.A. 33111' 'S.O.C. 14879'\n",
            " '2680' '1601' '348123' '349208' '374746' '248738' '364516' '345767'\n",
            " '345779' '330932' '113059' 'SO/C 14885' '3101278' 'W./C. 6608'\n",
            " 'SOTON/OQ 392086' '343275' '343276' '347466' 'W.E.P. 5734' 'C.A. 2315'\n",
            " '364500' '374910' 'PC 17754' 'PC 17759' '231919' '244367' '349245'\n",
            " '349215' '35281' '7540' '3101276' '349207' '343120' '312991' '349249'\n",
            " '371110' '110465' '2665' '324669' '4136' '2627' 'STON/O 2. 3101294'\n",
            " '370369' 'PC 17558' 'A4. 54510' '27267' '370372' 'C 17369' '2668'\n",
            " '347061' '349241' 'SOTON/O.Q. 3101307' 'A/5. 3337' '228414' 'C.A. 29178'\n",
            " 'SC/PARIS 2133' '11752' '7534' 'PC 17593' '2678' '347081'\n",
            " 'STON/O2. 3101279' '365222' '231945' 'C.A. 33112' '350043' '230080'\n",
            " '244310' 'S.O.P. 1166' '113776' 'A.5. 11206' 'A/5. 851' 'Fa 265302'\n",
            " 'PC 17597' '35851' 'SOTON/OQ 392090' '315037' 'CA. 2343' '371362'\n",
            " 'C.A. 33595' '347068' '315093' '363291' '113505' 'PC 17318' '111240'\n",
            " 'STON/O 2. 3101280' '17764' '350404' '4133' 'PC 17595' '250653' 'LINE'\n",
            " 'SC/PARIS 2131' '230136' '315153' '113767' '370365' '111428' '364849'\n",
            " '349247' '234604' '28424' '350046' 'PC 17610' '368703' '4579' '370370'\n",
            " '248747' '345770' '3101264' '2628' 'A/5 3540' '347054' '2699' '367231'\n",
            " '112277' 'SOTON/O.Q. 3101311' 'F.C.C. 13528' 'A/5 21174' '250646'\n",
            " '367229' '35273' 'STON/O2. 3101283' '243847' '11813' 'W/C 14208'\n",
            " 'SOTON/OQ 392089' '220367' '21440' '349234' '19943' 'PP 4348' 'SW/PP 751'\n",
            " 'A/5 21173' '236171' '347067' '237442' 'C.A. 29566' 'W./C. 6609' '26707'\n",
            " 'C.A. 31921' '28665' 'SCO/W 1585' '367230' 'W./C. 14263'\n",
            " 'STON/O 2. 3101275' '2694' '19928' '347071' '250649' '11751' '244252'\n",
            " '362316' '113514' 'A/5. 3336' '370129' '2650' 'PC 17585' '110152'\n",
            " 'PC 17755' '230433' '384461' '110413' '112059' '382649' 'C.A. 17248'\n",
            " '347083' 'PC 17582' 'PC 17760' '113798' '250644' 'PC 17596' '370375'\n",
            " '13502' '347073' '239853' 'C.A. 2673' '336439' '347464' '345778'\n",
            " 'A/5. 10482' '113056' '349239' '345774' '349206' '237798' '370373'\n",
            " '19877' '11967' 'SC/Paris 2163' '349236' '349233' 'PC 17612' '2693'\n",
            " '113781' '19988' '9234' '367226' '226593' 'A/5 2466' '17421' 'PC 17758'\n",
            " 'P/PP 3381' 'PC 17485' '11767' 'PC 17608' '250651' '349243'\n",
            " 'F.C.C. 13529' '347470' '29011' '36928' '16966' 'A/5 21172' '349219'\n",
            " '234818' '345364' '28551' '111361' '113043' 'PC 17611' '349225' '7598'\n",
            " '113784' '248740' '244361' '229236' '248733' '31418' '386525'\n",
            " 'C.A. 37671' '315088' '7267' '113510' '2695' '2647' '345783' '237671'\n",
            " '330931' '330980' 'SC/PARIS 2167' '2691' 'SOTON/O.Q. 3101310' 'C 7076'\n",
            " '110813' '2626' '14313' 'PC 17477' '11765' '3101267' '323951' 'C 7077'\n",
            " '113503' '2648' '347069' 'PC 17757' '2653' 'STON/O 2. 3101293' '349227'\n",
            " '27849' '367655' 'SC 1748' '113760' '350034' '3101277' '350052' '350407'\n",
            " '28403' '244278' '240929' 'STON/O 2. 3101289' '341826' '4137' '315096'\n",
            " '28664' '347064' '29106' '312992' '349222' '394140' 'STON/O 2. 3101269'\n",
            " '343095' '28220' '250652' '28228' '345773' '349254' 'A/5. 13032' '315082'\n",
            " '347080' 'A/4. 34244' '2003' '250655' '364851' 'SOTON/O.Q. 392078'\n",
            " '110564' '376564' 'SC/AH 3085' 'STON/O 2. 3101274' '13507' 'C.A. 18723'\n",
            " '345769' '347076' '230434' '65306' '33638' '113794' '2666' '113786'\n",
            " '65303' '113051' '17453' 'A/5 2817' '349240' '13509' '17464'\n",
            " 'F.C.C. 13531' '371060' '19952' '364506' '111320' '234360' 'A/S 2816'\n",
            " 'SOTON/O.Q. 3101306' '113792' '36209' '323592' '315089' 'SC/AH Basle 541'\n",
            " '7553' '31027' '3460' '350060' '3101298' '239854' 'A/5 3594' '4134'\n",
            " '11771' 'A.5. 18509' '65304' 'SOTON/OQ 3101317' '113787' 'PC 17609'\n",
            " 'A/4 45380' '36947' 'C.A. 6212' '350035' '315086' '364846' '330909'\n",
            " '4135' '26360' '111427' 'C 4001' '382651' 'SOTON/OQ 3101316' 'PC 17473'\n",
            " 'PC 17603' '349209' '36967' 'C.A. 34260' '226875' '349242' '12749'\n",
            " '349252' '2624' '2700' '367232' 'W./C. 14258' 'PC 17483' '3101296'\n",
            " '29104' '2641' '2690' '315084' '113050' 'PC 17761' '364498' '13568'\n",
            " 'WE/P 5735' '2908' '693' 'SC/PARIS 2146' '244358' '330979' '2620'\n",
            " '347085' '113807' '11755' '345572' '372622' '349251' '218629'\n",
            " 'SOTON/OQ 392082' 'SOTON/O.Q. 392087' 'A/4 48871' '349205' '2686'\n",
            " '350417' 'S.W./PP 752' '11769' 'PC 17474' '14312' 'A/4. 20589' '358585'\n",
            " '243880' '2689' 'STON/O 2. 3101286' '237789' '13049' '3411' '237565'\n",
            " '13567' '14973' 'A./5. 3235' 'STON/O 2. 3101273' 'A/5 3902' '364848'\n",
            " 'SC/AH 29037' '248727' '2664' '349214' '113796' '364511' '111426'\n",
            " '349910' '349246' '113804' 'SOTON/O.Q. 3101305' '370377' '364512'\n",
            " '220845' '31028' '2659' '11753' '350029' '54636' '36963' '219533'\n",
            " '349224' '334912' '27042' '347743' '13214' '112052' '237668'\n",
            " 'STON/O 2. 3101292' '350050' '349231' '13213' 'S.O./P.P. 751' 'CA. 2314'\n",
            " '349221' '8475' '330919' '365226' '349223' '29751' '2623' '5727' '349210'\n",
            " 'STON/O 2. 3101285' '234686' '312993' 'A/5 3536' '19996' '29750'\n",
            " 'F.C. 12750' 'C.A. 24580' '244270' '239856' '349912' '342826' '4138'\n",
            " '330935' '6563' '349228' '350036' '24160' '17474' '349256' '2672'\n",
            " '113800' '248731' '363592' '35852' '348121' 'PC 17475' '36864' '350025'\n",
            " '223596' 'PC 17476' 'PC 17482' '113028' '7545' '250647' '348124' '34218'\n",
            " '36568' '347062' '350048' '12233' '250643' '113806' '315094' '36866'\n",
            " '236853' 'STON/O2. 3101271' '239855' '28425' '233639' '349201' '349218'\n",
            " '16988' '376566' 'STON/O 2. 3101288' '250648' '113773' '335097' '29103'\n",
            " '392096' '345780' '349204' '350042' '29108' '363294' 'SOTON/O2 3101272'\n",
            " '2663' '347074' '112379' '364850' '8471' '345781' '350047' 'S.O./P.P. 3'\n",
            " '2674' '29105' '347078' '383121' '36865' '2687' '113501' 'W./C. 6607'\n",
            " 'SOTON/O.Q. 3101312' '374887' '3101265' '12460' 'PC 17600' '349203'\n",
            " '28213' '17465' '349244' '2685' '2625' '347089' '347063' '112050'\n",
            " '347087' '248723' '3474' '28206' '364499' '112058' 'STON/O2. 3101290'\n",
            " 'S.C./PARIS 2079' 'C 7075' '315098' '19972' '368323' '367228' '2671'\n",
            " '347468' '2223' 'PC 17756' '315097' '392092' '11774' 'SOTON/O2 3101287'\n",
            " '2683' '315090' 'C.A. 5547' '349213' '347060' 'PC 17592' '392091'\n",
            " '113055' '2629' '350026' '28134' '17466' '233866' '236852'\n",
            " 'SC/PARIS 2149' 'PC 17590' '345777' '349248' '695' '345765' '2667'\n",
            " '349212' '349217' '349257' '7552' 'C.A./SOTON 34068' 'SOTON/OQ 392076'\n",
            " '211536' '112053' '111369' '370376']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(type(trainX), type(trainY), type(valX), type(valY))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6gXvy9EGmy-j",
        "outputId": "9d83f799-86fb-4e08-f237-f41217e4fa55"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'> <class 'pandas.core.series.Series'> <class 'pandas.core.frame.DataFrame'> <class 'pandas.core.series.Series'>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# DenseFeautres에 들어가는 데이터를 미리 출력 해보고 싶을 때,\n",
        "\n",
        "ds_batch = ds.batch(32)\n",
        "\n",
        "next(iter(ds_batch))[0]\n",
        "\n",
        "feature_layer = tf.keras.layers.DenseFeatures(tf.feature_column.numeric_column('Fare'))\n",
        "feature_layer(next(iter(ds_batch))[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rjEP_cOPXLNA",
        "outputId": "9ad6579a-f96b-467b-ef6d-ff1dc636b8d3"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(32, 1), dtype=float32, numpy=\n",
              "array([[  7.25  ],\n",
              "       [ 71.2833],\n",
              "       [  7.925 ],\n",
              "       [ 53.1   ],\n",
              "       [  8.05  ],\n",
              "       [  8.4583],\n",
              "       [ 51.8625],\n",
              "       [ 21.075 ],\n",
              "       [ 11.1333],\n",
              "       [ 30.0708],\n",
              "       [ 16.7   ],\n",
              "       [ 26.55  ],\n",
              "       [  8.05  ],\n",
              "       [ 31.275 ],\n",
              "       [  7.8542],\n",
              "       [ 16.    ],\n",
              "       [ 29.125 ],\n",
              "       [ 13.    ],\n",
              "       [ 18.    ],\n",
              "       [  7.225 ],\n",
              "       [ 26.    ],\n",
              "       [ 13.    ],\n",
              "       [  8.0292],\n",
              "       [ 35.5   ],\n",
              "       [ 21.075 ],\n",
              "       [ 31.3875],\n",
              "       [  7.225 ],\n",
              "       [263.    ],\n",
              "       [  7.8792],\n",
              "       [  7.8958],\n",
              "       [ 27.7208],\n",
              "       [146.5208]], dtype=float32)>"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "model = tf.keras.Sequential([\n",
        "    tf.keras.layers.DenseFeatures(feature_columns), # 딕셔너리 데이터를 넣는 첫번째 레이어에는 위에서 만든 feature_columns 리스트를 넣어준다.\n",
        "    tf.keras.layers.Dense(128, activation = 'relu'),\n",
        "    tf.keras.layers.Dense(64, activation = 'relu'),\n",
        "    tf.keras.layers.Dropout(0.2), # overfitting 완화기능 : 윗 레이어의 노드 중 20%를 제거해주세요.\n",
        "    tf.keras.layers.Dense(1, activation = 'sigmoid'),\n",
        "])\n",
        "\n",
        "\n",
        "model.compile(optimizer='adam', loss = 'binary_crossentropy', metrics = ['accuracy'])\n",
        "# model.fit(trainX, trainY, validation_data = (valX, valY),  epochs = 20)\n",
        "\n",
        "# dataset을 batch를 뽑아서 넣아야한다. 그렇지 않으면 cannot have rank 0 에러가 난다 \n",
        "\n",
        "ds_batch = ds.batch(32) # 데이터 셋 자료를 32개씩 자르고 싶을때 .batch(32)를 이용해 자를 수 있다.\n",
        "\n",
        "model.fit(ds_batch, shuffle=True, epochs=20)\n",
        "\n",
        "# model.fit(ds_batch, validation_split = 0.2, shuffle = True, epochs = 20) 처럼 할수 없다.\n",
        "# batch dataset에는 validation_split을 할수가 없다. numpy_array나 tensor에만 validation_split=0.2를 할수있다.\n",
        "# model.fit(ds_batch, validation_data = (valX, valY), suffle = True, epochs = 20) 처럼 하기 위해서는\n",
        "# sklearn을 이용하는 방법이 있다. \n",
        "# 참고. 악플분석\n",
        "\n",
        "# from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "# X = pad_sequences(train_seq, maxlen=100)\n",
        "\n",
        "# from sklearn.model_selection import train_test_split\n",
        "\n",
        "# trainX, valX, trainY, valY = train_test_split( X, Y, test_size = 0.2, random_state = 42)\n",
        "\n",
        "# print(len(trainX))\n",
        "# print(len(valX))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YkjfnGLHRCLs",
        "outputId": "5bf088ab-98a3-435c-cfb7-0a5b33eaa159"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Layers in a Sequential model should only have a single input tensor. Received: inputs={'PassengerId': <tf.Tensor 'IteratorGetNext:5' shape=(None,) dtype=int64>, 'Pclass': <tf.Tensor 'IteratorGetNext:6' shape=(None,) dtype=int64>, 'Name': <tf.Tensor 'IteratorGetNext:3' shape=(None,) dtype=string>, 'Sex': <tf.Tensor 'IteratorGetNext:7' shape=(None,) dtype=string>, 'Age': <tf.Tensor 'IteratorGetNext:0' shape=(None,) dtype=float64>, 'SibSp': <tf.Tensor 'IteratorGetNext:8' shape=(None,) dtype=int64>, 'Parch': <tf.Tensor 'IteratorGetNext:4' shape=(None,) dtype=int64>, 'Ticket': <tf.Tensor 'IteratorGetNext:9' shape=(None,) dtype=string>, 'Fare': <tf.Tensor 'IteratorGetNext:2' shape=(None,) dtype=float64>, 'Embarked': <tf.Tensor 'IteratorGetNext:1' shape=(None,) dtype=string>}. Consider rewriting this model with the Functional API.\n",
            "WARNING:tensorflow:Layers in a Sequential model should only have a single input tensor. Received: inputs={'PassengerId': <tf.Tensor 'IteratorGetNext:5' shape=(None,) dtype=int64>, 'Pclass': <tf.Tensor 'IteratorGetNext:6' shape=(None,) dtype=int64>, 'Name': <tf.Tensor 'IteratorGetNext:3' shape=(None,) dtype=string>, 'Sex': <tf.Tensor 'IteratorGetNext:7' shape=(None,) dtype=string>, 'Age': <tf.Tensor 'IteratorGetNext:0' shape=(None,) dtype=float64>, 'SibSp': <tf.Tensor 'IteratorGetNext:8' shape=(None,) dtype=int64>, 'Parch': <tf.Tensor 'IteratorGetNext:4' shape=(None,) dtype=int64>, 'Ticket': <tf.Tensor 'IteratorGetNext:9' shape=(None,) dtype=string>, 'Fare': <tf.Tensor 'IteratorGetNext:2' shape=(None,) dtype=float64>, 'Embarked': <tf.Tensor 'IteratorGetNext:1' shape=(None,) dtype=string>}. Consider rewriting this model with the Functional API.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "28/28 [==============================] - 4s 34ms/step - loss: 0.6203 - accuracy: 0.7059\n",
            "Epoch 2/20\n",
            "28/28 [==============================] - 0s 12ms/step - loss: 0.5295 - accuracy: 0.7407\n",
            "Epoch 3/20\n",
            "28/28 [==============================] - 0s 13ms/step - loss: 0.4717 - accuracy: 0.7845\n",
            "Epoch 4/20\n",
            "28/28 [==============================] - 0s 12ms/step - loss: 0.4499 - accuracy: 0.7991\n",
            "Epoch 5/20\n",
            "28/28 [==============================] - 0s 8ms/step - loss: 0.4227 - accuracy: 0.8182\n",
            "Epoch 6/20\n",
            "28/28 [==============================] - 0s 7ms/step - loss: 0.4087 - accuracy: 0.8227\n",
            "Epoch 7/20\n",
            "28/28 [==============================] - 0s 7ms/step - loss: 0.3946 - accuracy: 0.8294\n",
            "Epoch 8/20\n",
            "28/28 [==============================] - 0s 7ms/step - loss: 0.3678 - accuracy: 0.8496\n",
            "Epoch 9/20\n",
            "28/28 [==============================] - 0s 7ms/step - loss: 0.3324 - accuracy: 0.8653\n",
            "Epoch 10/20\n",
            "28/28 [==============================] - 0s 7ms/step - loss: 0.3069 - accuracy: 0.8743\n",
            "Epoch 11/20\n",
            "28/28 [==============================] - 0s 7ms/step - loss: 0.2974 - accuracy: 0.8754\n",
            "Epoch 12/20\n",
            "28/28 [==============================] - 0s 8ms/step - loss: 0.2564 - accuracy: 0.8956\n",
            "Epoch 13/20\n",
            "28/28 [==============================] - 0s 7ms/step - loss: 0.2427 - accuracy: 0.9024\n",
            "Epoch 14/20\n",
            "28/28 [==============================] - 0s 7ms/step - loss: 0.1976 - accuracy: 0.9237\n",
            "Epoch 15/20\n",
            "28/28 [==============================] - 0s 7ms/step - loss: 0.1723 - accuracy: 0.9383\n",
            "Epoch 16/20\n",
            "28/28 [==============================] - 0s 7ms/step - loss: 0.1517 - accuracy: 0.9461\n",
            "Epoch 17/20\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.1338 - accuracy: 0.9551\n",
            "Epoch 18/20\n",
            "28/28 [==============================] - 0s 7ms/step - loss: 0.1252 - accuracy: 0.9630\n",
            "Epoch 19/20\n",
            "28/28 [==============================] - 0s 7ms/step - loss: 0.1129 - accuracy: 0.9630\n",
            "Epoch 20/20\n",
            "28/28 [==============================] - 0s 7ms/step - loss: 0.1106 - accuracy: 0.9630\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fe449b715a0>"
            ]
          },
          "metadata": {},
          "execution_count": 44
        }
      ]
    }
  ]
}